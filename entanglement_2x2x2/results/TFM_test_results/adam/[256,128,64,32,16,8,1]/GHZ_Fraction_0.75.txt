#Tensor product hilbert space dimension: 8; Number of simulations: 10;
#separable states were read from: /home/julio/Documents/my_projects/TFM/code/entanglement_2x2x2/input_data/100k/separable.txt; GHZ states were read from: /home/julio/Documents/my_projects/TFM/code/entanglement_2x2x2/input_data/100k/GHZ.txt;
#Architecture of the MLP: [256, 128, 64, 32, 16, 8, 1]; Number of epochs: 100; Fraction of DMs used for training: 0.75;
#Activation function in the hidden layers: relu; Activation function in the output layer: sigmoid; Loss function: binary_crossentropy;
#Optimizer: Adam; Batch size: 40; Test tolerance: 0.5;
#Sucess rate averaged over every simulation and over every sample in the test set: 84.05260000000001%
#Sample standard deviation for averaged success rate: 0.07618588231949543%
#Epoch	Loss	Loss sample STD	Val. Loss	V.L. sample STD
1	0.693153	0.000053	0.692457	0.000499
2	0.684254	0.003274	0.671624	0.006701
3	0.652481	0.010155	0.625799	0.015571
4	0.596258	0.021628	0.571623	0.025130
5	0.536376	0.028632	0.514232	0.030492
6	0.487537	0.034084	0.478016	0.035467
7	0.456246	0.038369	0.452986	0.038536
8	0.432991	0.041696	0.430490	0.041981
9	0.414706	0.044530	0.417415	0.044015
10	0.401326	0.046665	0.402310	0.046733
11	0.390572	0.048371	0.395561	0.047488
12	0.381669	0.049750	0.387731	0.048969
13	0.374518	0.050846	0.379966	0.050017
14	0.367052	0.051976	0.372638	0.051261
15	0.360968	0.052910	0.372364	0.051232
16	0.355761	0.053726	0.367063	0.052200
17	0.265859	0.007644	0.274318	0.009678
18	0.260813	0.007433	0.272354	0.011740
19	0.256016	0.007337	0.271557	0.010343
20	0.251667	0.007255	0.273627	0.009777
21	0.248075	0.007064	0.267375	0.010872
22	0.244115	0.006963	0.256969	0.009749
23	0.240695	0.006750	0.255040	0.009340
24	0.237712	0.006554	0.259015	0.009314
25	0.234560	0.006470	0.254755	0.009463
26	0.231726	0.006405	0.253593	0.010097
27	0.228847	0.006246	0.249411	0.010929
28	0.226291	0.006019	0.251550	0.010557
29	0.223457	0.006237	0.243420	0.009936
30	0.221019	0.005926	0.240986	0.010418
31	0.219072	0.005754	0.240045	0.011433
32	0.216628	0.005723	0.241759	0.010239
33	0.214716	0.005660	0.239235	0.011787
34	0.212677	0.005487	0.243989	0.010799
35	0.210869	0.005273	0.237373	0.010177
36	0.209275	0.005446	0.238567	0.009124
37	0.207639	0.005242	0.230304	0.009905
38	0.205764	0.005179	0.231270	0.012086
39	0.204441	0.005137	0.232870	0.010111
40	0.203097	0.005074	0.234072	0.011306
41	0.201403	0.004919	0.233093	0.010137
42	0.199548	0.004894	0.229012	0.011312
43	0.198231	0.004935	0.230433	0.010153
44	0.196565	0.004776	0.226322	0.010867
45	0.194946	0.004751	0.226653	0.011340
46	0.193951	0.004700	0.226658	0.010591
47	0.192795	0.004773	0.224266	0.011827
48	0.191634	0.004700	0.225441	0.010514
49	0.189988	0.004590	0.225852	0.011706
50	0.188763	0.004456	0.225888	0.010168
51	0.187768	0.004421	0.224793	0.010609
52	0.185805	0.004329	0.227789	0.011502
53	0.185372	0.004191	0.223579	0.012443
54	0.183842	0.004678	0.226514	0.012973
55	0.182929	0.004910	0.224348	0.013110
56	0.181550	0.004811	0.222895	0.014095
57	0.180544	0.004776	0.222147	0.011622
58	0.179850	0.004644	0.225777	0.012968
59	0.178108	0.004581	0.228160	0.013351
60	0.177954	0.004606	0.224213	0.013761
61	0.176256	0.004532	0.224658	0.013863
62	0.175198	0.004355	0.222080	0.014475
63	0.174457	0.004277	0.224528	0.013317
64	0.173413	0.004529	0.220873	0.013395
65	0.173013	0.004235	0.224420	0.014428
66	0.171851	0.004266	0.225068	0.015426
67	0.171020	0.004256	0.230113	0.013823
68	0.169851	0.004195	0.221679	0.014730
69	0.168748	0.004087	0.224324	0.014155
70	0.168348	0.004661	0.233074	0.014916
71	0.167592	0.004732	0.235543	0.017547
72	0.166681	0.004612	0.227002	0.017902
73	0.160867	0.002081	0.208556	0.003218
74	0.160755	0.001980	0.205699	0.001946
75	0.159776	0.002048	0.206897	0.003696
76	0.158816	0.002567	0.207707	0.005650
77	0.157798	0.002518	0.205540	0.004146
78	0.157096	0.002630	0.208840	0.005244
79	0.156387	0.002693	0.204494	0.003083
80	0.156150	0.002761	0.209806	0.005319
81	0.153257	0.002578	0.206587	0.004701
82	0.155118	0.002499	0.207146	0.002471
83	0.154897	0.002541	0.198352	0.000115
84	0.154477	0.002604	0.203768	0.002117
85	0.153805	0.002409	0.205899	0.006089
86	0.152486	0.002546	0.203164	0.002020
87	0.152593	0.001898	0.203638	0.001552
88	0.156161	0.000000	0.202346	0.000000
89	0.154969	0.000000	0.195730	0.000000
90	0.154971	0.000000	0.196942	0.000000
91	0.153192	0.000000	0.205543	0.000000
92	0.151837	0.000000	0.200376	0.000000
93	0.152824	0.000000	0.204316	0.000000
