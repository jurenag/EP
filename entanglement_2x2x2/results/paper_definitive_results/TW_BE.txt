#Tensor product hilbert space dimension: 8; Number of simulations: 10;
#Separable states were read from: /home/julio/Documents/entanglement_paper/updated_TFM_code/entanglement_2x2x2/input_data/generated_for_paper/100k/separable.txt; Bipartitely entangled states were read from: /home/julio/Documents/entanglement_paper/updated_TFM_code/entanglement_2x2x2/input_data/generated_for_paper/100k/BE.txt;
#Architecture of the MLP: [512, 256, 128, 32, 1]; Number of epochs: 125; Fraction of DMs used for training: 0.75;
#Activation function in the hidden layers: relu; Activation function in the output layer: sigmoid; Loss function: binary_crossentropy;
#Optimizer: adam; Batch size: 40; Test tolerance: 0.5;
#Sucess rate averaged over every simulation and over every sample in the test set: 95.45479999999999%
#Sample standard deviation for averaged success rate: 0.19965714612862395%
#Same average success rate for supplementary tests: [98.8643  87.59035]% <- [W, GHZ]
#Sample STD for averaged success rate in supplementary tests: [0.09308129 0.20470864]%
#
#       Further info on simulation parameters
# 
#       N=8;                                   
#       howManyTimes = 10;                     
#       architecture = [512,256,128,32,1];     
#       max_nepochs = 125;                     
#       fraction=0.75;                         
#       actHL = 'relu';                        
#       lastAct = 'sigmoid';                   
#       loss_f = 'binary_crossentropy'         
#       batch_size = 40;                      
#       output_file = cwd + '/results/paper_definitive_results/TW_BE.txt'
#       opt = 'adam'                        
#       take_supplementary_tests = True     
#       tol = 0.5                           
#       study_val_loss = True               
#       early_stopping = True               
#       skipped_rows = (0,0,0,0,0,0)        
#       pre_shuffle = True                  
#       first_type = 'Separable'            
#       second_type= 'Bipartitely entangled'
#       metric = 'val_loss'                 
#       epochs_to_wait = 25                 
#       min_delta = 1e-3     
#
#       loss_evolution, loss_evolution_std, ASR,        \
#       ASRSTD, ASR2, ASRSTD2, val_loss, val_loss_std,  \
#       reached_this_epoch, longest_training =          \
#       binaryOutput_formatData_trainNN_averageLoss_averageTestResults_and_writeResults(N, howManyTimes, first_filepath, 
#                                                                                       first_type, second_filepath, 
#                                                                                       second_type, architecture, 
#                                                                                       max_nepochs, fraction, 
#                                                                                       actHL, lastAct, loss_f, 
#                                                                                       batch_size, optimizer=opt, 
#                                                                                       perform_additional_tests=take_supplementary_tests, 
#                                                                                       first_test_filepath=additional_separable_filepaths, 
#                                                                                       second_test_filepath=additional_entangled_filepaths, 
#                                                                                       outFilePath=output_file, tolerance=tol, 
#                                                                                       use_validation_data=study_val_loss, 
#                                                                                       trigger_early_stopping=early_stopping, 
#                                                                                       metric_to_monitor=metric, 
#                                                                                       epochs_patience=epochs_to_wait, 
#                                                                                       min_improvement=min_delta, monitor_mode='min', 
#                                                                                       baseline=None, 
#                                                                                       recover_best_configuration=True, 
#                                                                                       first_label=0.0, second_label=1.0, 
#                                                                                       shuffle=pre_shuffle, rts=skipped_rows, 
#                                                                                       verb=0, snitch_every=1)               
#
#       reached_this_epoch, longest_training = [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
#                                               10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  9  8
#                                               8  8  6  6  6  6  4  1], 56
#
#Epoch	Loss	Loss sample STD	Val. Loss	V.L. sample STD
1	0.654346	0.001952	0.596541	0.003597
2	0.496333	0.006133	0.420351	0.011511
3	0.373750	0.011386	0.357674	0.011195
4	0.320167	0.012194	0.317383	0.015560
5	0.285063	0.012348	0.290082	0.011634
6	0.258576	0.012093	0.267905	0.013709
7	0.237933	0.011441	0.254421	0.013324
8	0.220124	0.010503	0.237337	0.012749
9	0.203751	0.009646	0.224412	0.010553
10	0.189936	0.008623	0.218064	0.010841
11	0.177966	0.008009	0.210227	0.010574
12	0.167005	0.007458	0.198302	0.009216
13	0.157121	0.007156	0.187229	0.007980
14	0.148835	0.006684	0.190658	0.009190
15	0.141365	0.006224	0.179340	0.010075
16	0.134279	0.005894	0.170216	0.007296
17	0.128311	0.005544	0.170510	0.007100
18	0.122548	0.005238	0.166945	0.007934
19	0.117260	0.004982	0.164681	0.005977
20	0.112798	0.004807	0.159888	0.006737
21	0.108276	0.004557	0.158228	0.006567
22	0.104365	0.004382	0.159786	0.007216
23	0.100623	0.004190	0.155430	0.005745
24	0.096656	0.004036	0.157373	0.006435
25	0.093629	0.003925	0.156144	0.005415
26	0.090506	0.003737	0.158183	0.005162
27	0.087465	0.003698	0.157286	0.005781
28	0.084926	0.003447	0.156234	0.006072
29	0.081671	0.003465	0.154926	0.005270
30	0.079505	0.003377	0.155885	0.005242
31	0.076686	0.003214	0.156445	0.005567
32	0.074530	0.003109	0.159103	0.005176
33	0.072770	0.003067	0.158000	0.004759
34	0.070190	0.002975	0.155624	0.004833
35	0.068213	0.002893	0.164868	0.004539
36	0.066376	0.002839	0.160340	0.005750
37	0.064384	0.002793	0.164947	0.004077
38	0.062972	0.002604	0.164586	0.006647
39	0.061135	0.002646	0.162159	0.004932
40	0.059502	0.002597	0.170539	0.004910
41	0.057845	0.002497	0.169009	0.002885
42	0.056458	0.002429	0.161650	0.005715
43	0.054916	0.002401	0.169243	0.004480
44	0.053601	0.002292	0.173321	0.006754
45	0.052225	0.002287	0.176861	0.003976
46	0.051079	0.002119	0.176816	0.005153
47	0.050038	0.002415	0.177167	0.004788
48	0.050591	0.002145	0.185255	0.004064
49	0.048931	0.002063	0.183382	0.006234
50	0.047913	0.002134	0.181095	0.004919
51	0.045928	0.002005	0.179736	0.004123
52	0.044638	0.001921	0.177892	0.006801
53	0.043892	0.001728	0.194125	0.004452
54	0.042770	0.001824	0.185284	0.004575
55	0.039714	0.001328	0.189117	0.001955
56	0.040293	0.000000	0.198246	0.000000