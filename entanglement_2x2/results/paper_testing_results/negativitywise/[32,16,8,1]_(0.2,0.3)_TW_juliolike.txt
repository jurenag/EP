#Tensor product hilbert space dimension: 4; Number of simulations: 10;
#Separable DMs were read from: /home/julio/Documents/entanglement_paper/updated_TFM_code/entanglement_2x2/input_data/received_from_DM/pure_states/separable.txt; Entangled w/ [0.2,0.3] neg. juliolike DMs were read from: /home/julio/Documents/entanglement_paper/updated_TFM_code/entanglement_2x2/input_data/generated/pure_states/juliolike/negativity_(0.2, 0.3).txt;
#Architecture of the MLP: [32, 16, 8, 1]; Number of epochs: 100; Fraction of DMs used for training: 0.8;
#Activation function in the hidden layers: relu; Activation function in the output layer: sigmoid; Loss function: binary_crossentropy;
#Optimizer: rmsprop; Batch size: 40; Test tolerance: 0.5;
#tf.Keras.callbacks.EarlyStopping was used with: metric:val_loss; Epochs patience:25; Minimum improvement:0.001;
#Sucess rate averaged over every simulation and over every sample in the test set: 99.86749999999999%
#Sample standard deviation for averaged success rate: 0.3684350349791395%
#Same average success rate for supplementary tests: [0.5176699999999999, 0.8146100000000001, 0.9996700000000001, 0.9998950000000001, 0.9998950000000001, 0.52393, 0.82204, 0.99828, 0.9998950000000001, 0.9998950000000001, 0.9917100000000001, 0.9991549999999999, 0.9995149999999999, 0.9995149999999999, 0.9995149999999999]%
#Sample STD for averaged success rate in supplementary tests: [0.15327484173862332, 0.08918606836272126, 0.0018409535572591136, 0.001024156970374526, 0.001024156970374526, 0.1515593464950281, 0.08637953368709514, 0.0045721067354146175, 0.0010241569703853665, 0.001024156970374526, 0.013361421705791618, 0.0034610110517040403, 0.002219566962272437, 0.002219566962272437, 0.002219566962272437]%
#Epoch	Loss	Loss sample STD	Val. Loss	V.L. sample STD
1	0.666843	0.002221	0.629255	0.004643
2	0.576109	0.006182	0.533172	0.006162
3	0.490065	0.009037	0.453228	0.012190
4	0.400641	0.017165	0.355416	0.021762
5	0.295873	0.024184	0.249430	0.026661
6	0.200089	0.024070	0.166569	0.022221
7	0.131889	0.018513	0.111042	0.015862
8	0.088792	0.012181	0.076958	0.009917
9	0.062847	0.007734	0.058985	0.007065
10	0.046978	0.005121	0.048934	0.003208
11	0.036621	0.003817	0.037300	0.003542
12	0.029692	0.002922	0.028825	0.002957
13	0.024866	0.002452	0.027052	0.002247
14	0.020838	0.002096	0.024485	0.002717
15	0.017821	0.001874	0.024165	0.002571
16	0.015730	0.001630	0.018289	0.001727
17	0.013837	0.001482	0.017186	0.001970
18	0.012197	0.001355	0.014834	0.001281
19	0.010970	0.001211	0.015724	0.001870
20	0.009510	0.001041	0.014041	0.002444
21	0.008784	0.001006	0.014438	0.001577
22	0.008052	0.000935	0.015167	0.001733
23	0.007506	0.000918	0.015595	0.003691
24	0.006893	0.000770	0.011172	0.001131
25	0.006301	0.000793	0.010812	0.001371
26	0.005758	0.000689	0.010876	0.001747
27	0.005368	0.000713	0.009974	0.001301
28	0.004989	0.000650	0.008598	0.000976
29	0.004615	0.000608	0.009029	0.001293
30	0.004114	0.000531	0.009365	0.001349
31	0.003941	0.000535	0.012194	0.002276
32	0.003819	0.000606	0.009103	0.001290
33	0.003313	0.000500	0.008232	0.001348
34	0.003218	0.000423	0.009462	0.001201
35	0.003019	0.000462	0.007204	0.000924
36	0.003030	0.000450	0.008225	0.001016
37	0.002903	0.000429	0.010013	0.002471
38	0.002770	0.000479	0.009528	0.001258
39	0.002483	0.000361	0.006942	0.000847
40	0.002411	0.000432	0.008925	0.001615
41	0.002108	0.000361	0.009404	0.001380
42	0.002191	0.000341	0.008188	0.001272
43	0.002092	0.000378	0.006240	0.000719
44	0.001947	0.000339	0.007819	0.001358
45	0.001919	0.000346	0.008554	0.002072
46	0.001642	0.000331	0.006874	0.000971
47	0.001717	0.000356	0.008022	0.000824
48	0.001627	0.000319	0.009436	0.001427
49	0.001644	0.000265	0.009632	0.002062
50	0.001798	0.000300	0.007112	0.000851
51	0.001438	0.000212	0.007237	0.000762
52	0.001474	0.000247	0.007541	0.001239
53	0.001494	0.000197	0.008044	0.000680
54	0.001561	0.000252	0.006770	0.000867
55	0.001423	0.000227	0.014638	0.005232
56	0.001418	0.000180	0.007286	0.001163
57	0.001339	0.000284	0.008108	0.001461
58	0.001106	0.000264	0.007388	0.001097
59	0.001250	0.000196	0.008058	0.001157
60	0.001146	0.000209	0.008224	0.001841
61	0.001094	0.000180	0.007180	0.001015
62	0.001189	0.000218	0.007366	0.001026
63	0.001100	0.000204	0.007589	0.001784
64	0.001048	0.000181	0.006461	0.000855
65	0.001129	0.000177	0.012220	0.003552
66	0.001105	0.000226	0.010736	0.003243
67	0.000999	0.000147	0.011131	0.002174
68	0.000911	0.000096	0.007817	0.001038
69	0.000889	0.000124	0.009655	0.002269
70	0.000777	0.000130	0.010555	0.001650
71	0.001089	0.000109	0.007537	0.000875
72	0.001221	0.000179	0.008079	0.002850
73	0.001008	0.000128	0.009627	0.002782
74	0.001126	0.000165	0.008451	0.001612
75	0.001206	0.000244	0.005942	0.002261
76	0.001099	0.000364	0.007840	0.001854
77	0.000911	0.000138	0.007861	0.002259
78	0.000968	0.000092	0.011083	0.000201
79	0.000894	0.000178	0.007998	0.000833
80	0.000801	0.000113	0.010444	0.002243
81	0.000954	0.000094	0.008751	0.001544
82	0.000954	0.000164	0.008908	0.001914
83	0.000766	0.000165	0.006256	0.001956
84	0.000645	0.000078	0.008395	0.001301
85	0.000752	0.000077	0.006518	0.001439
86	0.001128	0.000125	0.009854	0.000753
87	0.000954	0.000217	0.007542	0.000074
88	0.001091	0.000039	0.014012	0.001635
89	0.000741	0.000073	0.011428	0.003951
90	0.001127	0.000089	0.011094	0.001739
91	0.000896	0.000142	0.006334	0.002331
92	0.001500	0.000571	0.007772	0.002800
93	0.000725	0.000083	0.006192	0.002062
94	0.000933	0.000071	0.009290	0.000358
95	0.000977	0.000181	0.006505	0.002545
96	0.000739	0.000074	0.007925	0.002168
97	0.000821	0.000008	0.012056	0.007324
98	0.000774	0.000000	0.002663	0.000000
99	0.000577	0.000000	0.011691	0.000000
100	0.000396	0.000000	0.004560	0.000000
